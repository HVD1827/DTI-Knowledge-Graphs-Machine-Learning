{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":106.211014,"end_time":"2023-10-08T08:39:37.882520","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-10-08T08:37:51.671506","version":"2.4.0"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.416778,"end_time":"2023-10-08T08:37:55.167635","exception":false,"start_time":"2023-10-08T08:37:54.750857","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.003317,"end_time":"2023-10-08T08:37:55.177242","exception":false,"start_time":"2023-10-08T08:37:55.173925","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nEntities_Embedding_file = '/kaggle/input/gpcr-ic-result-3-mai/gpcr_ic_results_3_mai/ic/dict_ic.list'\nEntities_Embedding_List = {}\nIdEntiy__Embedding_List = {}\nproteinidlist=[]\nproteinnamelist=[]\ndrugidlist=[]\nwith open(Entities_Embedding_file) as f:\n    for line in f:\n        it = line.strip().split(\"\\t\")\n        id = int(it[0])\n        entity = str(it[1])\n        if id > 168:\n            proteinidlist.append(id)\n            proteinnamelist.append(entity)\n            if entity not in Entities_Embedding_List:\n                Entities_Embedding_List[entity] = set()\n            Entities_Embedding_List[entity].add(int(id))\n            if id not in IdEntiy__Embedding_List:\n                IdEntiy__Embedding_List[id] = set()\n            IdEntiy__Embedding_List[id].add(str(entity))\n        else:\n            drugidlist.append(id)\nprint(len(proteinnamelist))\n\n\n        \n\n","metadata":{"papermill":{"duration":1.322726,"end_time":"2023-10-08T08:37:56.503193","exception":false,"start_time":"2023-10-08T08:37:55.180467","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load entity embeddings\nentity_embeddings = np.loadtxt('/kaggle/input/gpcr-ic-result-3-mai/gpcr_ic_results_3_mai/ic/entity_embedding_dt_ic.csv')\n\n# Your other code here...\n\n# Assuming embedcosinusDrugslist, embedcosinusProteinslist, and embedcosinusTargetlist \n# contain the indices of drugs, proteins, and targets respectively\nsubembedding=entity_embeddings[proteinidlist]\nprint(len(subembedding))\nprint(subembedding)\n# Calculate cosine similarities between proteins\nsimilarities_proteins = cosine_similarity(subembedding)\n\n\n# Now similarities_proteins contains cosine similarities between proteins\n","metadata":{"papermill":{"duration":0.113976,"end_time":"2023-10-08T08:37:56.620721","exception":false,"start_time":"2023-10-08T08:37:56.506745","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Combination with Protbert Embedding******","metadata":{"papermill":{"duration":0.006387,"end_time":"2023-10-08T08:37:56.633403","exception":false,"start_time":"2023-10-08T08:37:56.627016","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"import numpy as np\nloaded_ids_prot_e_protbert = np.load('/kaggle/input/protbertembedding/protein_e_ids.npy')\n# Extract UniProt identifiers using list comprehension\nuniport_identifiers = [entry.split('|')[1] for entry in loaded_ids_prot_e_protbert]\n#print(uniport_identifiers)\n####################\nprotein_dict = {}\n\n# List to store duplicates\nduplicates = []\n\n# Iterate through the protein list\nfor index,protein in enumerate(uniport_identifiers):\n    # If the protein identifier is already in the dictionary, it's a duplicate\n    if protein in protein_dict:\n        duplicates.append(protein+\">\"+str(index))\n    else:\n        # Add the protein identifier to the dictionary\n        protein_dict[protein] = True\n\n# Print the duplicates\nprint(\"Duplicates in the list are:\", duplicates)\nuniport_identifiers.pop(554)\n##################\"\"\"\"\"\"\nloaded_embedding_prot_e_protbert = np.load('/kaggle/input/protbertembedding/protbert_e_embeddings.npy')\n# Index of the vector you want to delete\nindex_to_delete = 1\nprint(\"loaded_embedding_prot_e_protbert.shape()\")\nprint(loaded_embedding_prot_e_protbert.shape)\n# Delete the vector at the specified index\nloaded_embedding_prot_e_protbert_md = np.delete(loaded_embedding_prot_e_protbert, 554, axis=0)\nprint(len(loaded_ids_prot_e_protbert))\nprint(len(loaded_embedding_prot_e_protbert))\nfrom sklearn.decomposition import PCA\ndesired_components = 400\n\n# Apply PCA to loaded_embedding_prot_e_protbert_md\npca = PCA(n_components=desired_components)\nloaded_embedding_prot_e_protbert_md_pca = pca.fit_transform(loaded_embedding_prot_e_protbert_md)\n#combined_embeddings = np.concatenate((loaded_embedding_prot_e_protbert_md_pca, subembedding), axis=0)\n#print(\"combined_embeddings.shape()\")\n#print(combined_embeddings.shape)\nsubembeddingdrugs=entity_embeddings[drugidlist]\ncombined_embeddings = np.concatenate((subembeddingdrugs, loaded_embedding_prot_e_protbert_md_pca), axis=0)\nprint(\"combined_embeddings.shape()\")\nprint(combined_embeddings.shape)\nnp.savetxt(\n        os.path.join('/kaggle/working/entity_embedding_dt_e_withprotbert.csv'),\n        combined_embeddings\n    )\nsimilarities_proteins = cosine_similarity(loaded_embedding_prot_e_protbert_md_pca)","metadata":{"execution":{"iopub.execute_input":"2023-10-07T21:50:01.247574Z","iopub.status.busy":"2023-10-07T21:50:01.247302Z","iopub.status.idle":"2023-10-07T21:50:02.496457Z","shell.execute_reply":"2023-10-07T21:50:02.494856Z","shell.execute_reply.started":"2023-10-07T21:50:01.247552Z"},"papermill":{"duration":0.00573,"end_time":"2023-10-08T08:37:56.645357","exception":false,"start_time":"2023-10-08T08:37:56.639627","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Save cosine similarities to a text file\nwith open('/kaggle/working/cosine_similarities_ic_proteins.txt', 'w') as f:\n    # Save drug similarities\n    for i, row in enumerate(similarities_proteins):\n        for j, similarity in enumerate(row):\n            protein1 = proteinnamelist[i]\n            protein2 = proteinnamelist[j]\n            f.write('{}\\t{}\\t{}\\n'.format(protein1, protein2, similarity))","metadata":{"papermill":{"duration":0.131439,"end_time":"2023-10-08T08:37:56.783124","exception":false,"start_time":"2023-10-08T08:37:56.651685","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import euclidean_distances\nsimilarities_protein_ECLD = euclidean_distances(entity_embeddings[proteinidlist])\n# Save cosine similarities to a text file\nwith open('/kaggle/working/eucludian_similarities_ic_proteins.txt', 'w') as f:\n    # Save drug similarities\n    for i, row in enumerate(similarities_protein_ECLD):\n        for j, similarity in enumerate(row):\n            protein1 = proteinnamelist[i]\n            protein2 = proteinnamelist[j]\n            f.write('{}\\t{}\\t{}\\n'.format(protein1, protein2, similarity))\n\n","metadata":{"papermill":{"duration":0.157293,"end_time":"2023-10-08T08:37:56.943985","exception":false,"start_time":"2023-10-08T08:37:56.786692","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import manhattan_distances\nsimilarities_proteins_mnht = manhattan_distances(entity_embeddings[proteinidlist])\n# Save cosine similarities to a text file\nwith open('/kaggle/working/manhatan_similarities_ic_proteins.txt', 'w') as f:\n    # Save drug similarities\n    for i, row in enumerate(similarities_proteins_mnht):\n        for j, similarity in enumerate(row):\n            protein1 = proteinnamelist[i]\n            protein2 = proteinnamelist[j]\n            f.write('{}\\t{}\\t{}\\n'.format(protein1, protein2, similarity))\n","metadata":{"papermill":{"duration":0.10798,"end_time":"2023-10-08T08:37:57.055649","exception":false,"start_time":"2023-10-08T08:37:56.947669","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import pearsonr\nsimilarities_proteins_pearson = np.array([[pearsonr(a, b)[0] for b in entity_embeddings[proteinidlist]] for a in entity_embeddings[proteinidlist]])\n# Save cosine similarities to a text file\nwith open('/kaggle/working/pearson_similarities_ic_proteins.txt', 'w') as f:\n    # Save drug similarities\n    for i, row in enumerate(similarities_proteins_pearson):\n        for j, similarity in enumerate(row):\n            protein1 = proteinnamelist[i]\n            protein2 = proteinnamelist[j]\n            f.write('{}\\t{}\\t{}\\n'.format(protein1, protein2, similarity))","metadata":{"papermill":{"duration":39.267975,"end_time":"2023-10-08T08:38:36.327206","exception":false,"start_time":"2023-10-08T08:37:57.059231","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from scipy.stats import pearsonr\nsimilarities_proteins = np.array([[pearsonr(a, b)[0] for b in entity_embeddings[proteinidlist]] for a in entity_embeddings[proteinidlist]])\n# Save cosine similarities to a text file\nwith open('/kaggle/working/pearsonr_similarities_e_proteins.txt', 'w') as f:\n    # Save drug similarities\n    for i, row in enumerate(similarities_proteins_mnht):\n        for j, similarity in enumerate(row):\n            protein1 = proteinnamelist[i]\n            protein2 = proteinnamelist[j]\n            f.write('{}\\t{}\\t{}\\n'.format(protein1, protein2, similarity))\n","metadata":{"execution":{"iopub.execute_input":"2023-10-07T08:08:41.476897Z","iopub.status.busy":"2023-10-07T08:08:41.476513Z"},"papermill":{"duration":0.003392,"end_time":"2023-10-08T08:38:36.334400","exception":false,"start_time":"2023-10-08T08:38:36.331008","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"import os\nimport numpy as np\nfrom scipy.stats import pearsonr\nfrom multiprocessing import Pool\n\n# Get the number of available CPU cores\nnum_processes = os.cpu_count()\nprint(\"num_processes\")\nprint(num_processes)\n\n# Assuming entity_embeddings is a NumPy array\ndef compute_similarity(i):\n    similarities = []\n    for j in range(len(entity_embeddings)):\n        similarity = pearsonr(entity_embeddings[i], entity_embeddings[j])[0]\n        similarities.append((i, j, similarity))\n    return similarities\n\n\npool = Pool(processes=num_processes)\n\n# Compute Pearson similarities using multiprocessing\nresults = pool.map(compute_similarity, range(len(entity_embeddings)))\npool.close()\npool.join()\n\n# Flatten the list of similarities from different processes\nsimilarities_proteins = [similarity for sublist in results for similarity in sublist]\n\n# Save Pearson similarities to a text file\nwith open('/kaggle/working/pearsonr_similarities_ic_drugs.txt', 'w') as f:\n    # Save protein similarities\n    for similarity in similarities_proteins:\n        protein1, protein2, similarity_value = similarity\n        f.write('{}\\t{}\\t{}\\n'.format(protein1, protein2, similarity_value))\n\nprint(\"End pearson embedding\")\n","metadata":{"execution":{"iopub.execute_input":"2023-10-07T21:50:05.335522Z","iopub.status.busy":"2023-10-07T21:50:05.335107Z"},"papermill":{"duration":0.00319,"end_time":"2023-10-08T08:38:36.341522","exception":false,"start_time":"2023-10-08T08:38:36.338332","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from sklearn.metrics import jaccard_score\n# Threshold for converting numerical values to binary (0 or 1)\nthreshold = 0.5  # You can adjust this threshold based on your data\n\n# Convert numerical values to binary based on the threshold\nbinary_protein_sets = [[int(value > threshold) for value in entity_embeddings[proteinid]] for proteinid in proteinidlist]\n\n# Calculate Jaccard similarities between proteins\nsimilarities_proteins_jaccard = np.array([[jaccard_score(set_a, set_b) for set_b in binary_protein_sets] for set_a in binary_protein_sets])\nwith open('/kaggle/working/jaccard_similarities_ic_proteins.txt', 'w') as f:\n    # Save drug similarities\n    for i, row in enumerate(similarities_proteins_jaccard):\n        for j, similarity in enumerate(row):\n            protein1 = proteinnamelist[i]\n            protein2 = proteinnamelist[j]\n            f.write('{}\\t{}\\t{}\\n'.format(protein1, protein2, similarity))","metadata":{"papermill":{"duration":61.01301,"end_time":"2023-10-08T08:39:37.357955","exception":false,"start_time":"2023-10-08T08:38:36.344945","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}
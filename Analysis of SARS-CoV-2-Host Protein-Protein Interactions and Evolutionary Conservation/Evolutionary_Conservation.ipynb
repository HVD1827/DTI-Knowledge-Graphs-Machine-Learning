{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc43bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ppi = pd.read_csv(\"10090.protein.links.v12.0.txt\", sep=\" \")\n",
    "ppi = ppi[ppi['combined_score'] > 700] \n",
    "\n",
    "ppi[['protein1', 'protein2']] = ppi[['protein1', 'protein2']].apply(lambda col: col.str.split('.').str[1])\n",
    "ppi.to_csv(\"mouse_ppi_edges.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73cbb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb648ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"2020-03-18_Krogan_SARSCoV2_27baits.xlsx\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14dc028",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install biopython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import requests\n",
    "\n",
    "def safe_get_gene_symbol(enspid, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            url = f\"https://mygene.info/v3/query?q={enspid}&fields=symbol\"\n",
    "            response = requests.get(url, timeout=10)\n",
    "            if response.ok:\n",
    "                data = response.json()\n",
    "                return data.get(\"hits\", [{}])[0].get(\"symbol\")\n",
    "        except (requests.exceptions.SSLError, requests.exceptions.RequestException) as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for {enspid}: {e}\")\n",
    "            sleep(2 ** attempt)  # Exponential backoff\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530bdb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "\n",
    "CACHE_FILE = \"ensp_gene_cache.json\"\n",
    "\n",
    "def load_cache():\n",
    "    \"\"\"Load existing cache from file or return empty dict\"\"\"\n",
    "    if Path(CACHE_FILE).exists():\n",
    "        with open(CACHE_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache):\n",
    "    \"\"\"Save cache to file\"\"\"\n",
    "    with open(CACHE_FILE, 'w') as f:\n",
    "        json.dump(cache, f)\n",
    "\n",
    "gene_cache = load_cache()\n",
    "\n",
    "def safe_get_gene_symbol(enspid, max_retries=3):\n",
    "    \"\"\"\n",
    "    Fetch gene symbol with caching, retries, and dual API fallback\n",
    "    \"\"\"\n",
    "    if enspid in gene_cache:\n",
    "        return gene_cache[enspid]\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            url = f\"https://mygene.info/v3/query?q={enspid}&fields=symbol\"\n",
    "            response = requests.get(url, timeout=10)\n",
    "            \n",
    "            if response.ok:\n",
    "                data = response.json()\n",
    "                hits = data.get(\"hits\", [])\n",
    "                if hits:\n",
    "                    symbol = hits[0].get(\"symbol\")\n",
    "                    if symbol: \n",
    "                        gene_cache[enspid] = symbol\n",
    "                        return symbol\n",
    "            \n",
    "            ensembl_url = f\"https://rest.ensembl.org/lookup/id/{enspid}?content-type=application/json\"\n",
    "            ensembl_response = requests.get(ensembl_url, timeout=10)\n",
    "            \n",
    "            if ensembl_response.ok:\n",
    "                ensembl_data = ensembl_response.json()\n",
    "                symbol = ensembl_data.get(\"display_name\")\n",
    "                if symbol:  \n",
    "                    gene_cache[enspid] = symbol\n",
    "                    return symbol\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for {enspid}: {e}\")\n",
    "            sleep(2 ** attempt) \n",
    "    \n",
    "    print(f\"Could not resolve {enspid} after {max_retries} attempts\")\n",
    "    gene_cache[enspid] = None  \n",
    "    return None\n",
    "\n",
    "human_df = pd.read_csv(\"human_ppi_edges.csv\")\n",
    "\n",
    "unique_ids = set(human_df['protein1'].unique()).union(set(human_df['protein2'].unique()))\n",
    "print(f\"Total unique ENSP IDs to resolve: {len(unique_ids)}\")\n",
    "\n",
    "for i, enspid in enumerate(unique_ids, 1):\n",
    "    safe_get_gene_symbol(enspid)\n",
    "    if i % 100 == 0:  \n",
    "        save_cache(gene_cache)\n",
    "        print(f\"Processed {i}/{len(unique_ids)} IDs\")\n",
    "\n",
    "save_cache(gene_cache)\n",
    "\n",
    "human_df[\"protein1_gene\"] = human_df[\"protein1\"].map(gene_cache)\n",
    "human_df[\"protein2_gene\"] = human_df[\"protein2\"].map(gene_cache)\n",
    "\n",
    "human_filtered = human_df.dropna(subset=[\"protein1_gene\", \"protein2_gene\"])\n",
    "human_filtered.to_csv(\"human_ppi_edges_filtered.csv\", index=False)\n",
    "\n",
    "print(\"\\nProcessing complete!\")\n",
    "print(f\"Original edges: {len(human_df)}\")\n",
    "print(f\"Valid edges after mapping: {len(human_filtered)}\")\n",
    "print(f\"Cache size: {len(gene_cache)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d7eca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/Users/rajeevr/Downloads/DTIOG/ensp_gene_cache.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(len(data)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1580928",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcd7e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "\n",
    "# Cache setup\n",
    "CACHE_FILE = \"ensp_gene_cache_mouse.json\"\n",
    "\n",
    "def load_cache():\n",
    "    \"\"\"Load existing cache from file or return empty dict\"\"\"\n",
    "    if Path(CACHE_FILE).exists():\n",
    "        with open(CACHE_FILE, 'r') as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_cache(cache):\n",
    "    \"\"\"Save cache to file\"\"\"\n",
    "    with open(CACHE_FILE, 'w') as f:\n",
    "        json.dump(cache, f)\n",
    "\n",
    "gene_cache = load_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c32967",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def safe_get_gene_symbol(enspid, max_retries=3):\n",
    "    \"\"\"\n",
    "    Fetch gene symbol with caching, retries, and dual API fallback\n",
    "    \"\"\"\n",
    "    if enspid in gene_cache:\n",
    "        return gene_cache[enspid]\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            url = f\"https://mygene.info/v3/query?q={enspid}&fields=symbol\"\n",
    "            response = requests.get(url, timeout=10)\n",
    "            \n",
    "            if response.ok:\n",
    "                data = response.json()\n",
    "                hits = data.get(\"hits\", [])\n",
    "                if hits:\n",
    "                    symbol = hits[0].get(\"symbol\")\n",
    "                    if symbol:  # Only cache valid symbols\n",
    "                        gene_cache[enspid] = symbol\n",
    "                        return symbol\n",
    "            \n",
    "            ensembl_url = f\"https://rest.ensembl.org/lookup/id/{enspid}?content-type=application/json\"\n",
    "            ensembl_response = requests.get(ensembl_url, timeout=10)\n",
    "            \n",
    "            if ensembl_response.ok:\n",
    "                ensembl_data = ensembl_response.json()\n",
    "                symbol = ensembl_data.get(\"display_name\")\n",
    "                if symbol:  # Only cache valid symbols\n",
    "                    gene_cache[enspid] = symbol\n",
    "                    return symbol\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for {enspid}: {e}\")\n",
    "            sleep(2 ** attempt)  # Exponential backoff\n",
    "    \n",
    "    print(f\"Could not resolve {enspid} after {max_retries} attempts\")\n",
    "    gene_cache[enspid] = None  # Cache failures to avoid retrying\n",
    "    return None\n",
    "\n",
    "mouse_df = pd.read_csv(\"mouse_ppi_edges.csv\")\n",
    "\n",
    "unique_ids = set(mouse_df['protein1'].unique()).union(set(mouse_df['protein2'].unique()))\n",
    "print(f\"Total unique ENSP IDs to resolve: {len(unique_ids)}\")\n",
    "\n",
    "for i, enspid in enumerate(unique_ids, 1):\n",
    "    safe_get_gene_symbol(enspid)\n",
    "    if i % 100 == 0: \n",
    "        save_cache(gene_cache)\n",
    "        print(f\"Processed {i}/{len(unique_ids)} IDs\")\n",
    "\n",
    "save_cache(gene_cache)\n",
    "\n",
    "mouse_df[\"protein1_gene\"] = mouse_df[\"protein1\"].map(gene_cache)\n",
    "mouse_df[\"protein2_gene\"] = mouse_df[\"protein2\"].map(gene_cache)\n",
    "\n",
    "mouse_filtered = mouse_df.dropna(subset=[\"protein1_gene\", \"protein2_gene\"])\n",
    "mouse_filtered.to_csv(\"mouse_ppi_edges_filtered.csv\", index=False)\n",
    "\n",
    "print(\"\\nProcessing complete!\")\n",
    "print(f\"Original edges: {len(mouse_df)}\")\n",
    "print(f\"Valid edges after mapping: {len(mouse_filtered)}\")\n",
    "print(f\"Cache size: {len(gene_cache)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "krogan_df = pd.read_excel(\"2020-03-18_Krogan_SARSCoV2_27baits.xlsx\")\n",
    "human_df = pd.read_csv(\"human_ppi_edges_filtered.csv\")\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "for _, row in krogan_df.iterrows():\n",
    "    virus = row['Bait']\n",
    "    human = row['PreyGene']\n",
    "    G.add_edge(virus, human, interaction='viral-human')\n",
    "\n",
    "for _, row in human_df.iterrows():\n",
    "    G.add_edge(row['protein1_gene'], row['protein2_gene'], interaction='human-human')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9583d3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "viral_nodes = krogan_df['Bait'].unique()\n",
    "viral_subnetworks = {}\n",
    "\n",
    "for v in viral_nodes:\n",
    "    neighbors = list(G.neighbors(v))\n",
    "    subgraph_nodes = [v] + neighbors\n",
    "    subG = G.subgraph(subgraph_nodes)\n",
    "    viral_subnetworks[v] = subG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c466b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "results = []\n",
    "def is_conserved(h1, h2):\n",
    "    m1 = ortholog_map.get(h1)\n",
    "    m2 = ortholog_map.get(h2)\n",
    "    if not m1 or not m2:\n",
    "        return False\n",
    "    return tuple(sorted([m1, m2])) in mouse_edges\n",
    "\n",
    "for human in set(krogan_df['PreyGene']):\n",
    "    viral_partners = krogan_df[krogan_df['PreyGene'] == human]['Bait'].nunique()\n",
    "    degree = G.degree(human)\n",
    "    \n",
    "    # Check conservation\n",
    "    conserved = False\n",
    "    for neighbor in G.neighbors(human):\n",
    "        if G.edges[human, neighbor]['interaction'] == 'human-human' and is_conserved(human, neighbor):\n",
    "            conserved = True\n",
    "            break\n",
    "    \n",
    "    results.append({\n",
    "        'gene': human,\n",
    "        'viral_partners': viral_partners,\n",
    "        'degree': degree,\n",
    "        'conserved': conserved\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(by=['viral_partners', 'degree'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838be404",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"ranked_targets.csv\", index=False)\n",
    "\n",
    "nx.draw(viral_subnetworks['SARS-CoV2 E'], with_labels=True, node_size=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "human_df = pd.read_csv(\"human_ppi_edges_filtered.csv\")  # must have protein1_gene, protein2_gene\n",
    "\n",
    "G = nx.Graph()\n",
    "for _, row in human_df.iterrows():\n",
    "    G.add_edge(row['protein1_gene'], row['protein2_gene'])\n",
    "\n",
    "centrality = nx.degree_centrality(G)\n",
    "centrality_df = pd.DataFrame.from_dict(centrality, orient='index', columns=['centrality']).reset_index()\n",
    "centrality_df = centrality_df.rename(columns={'index': 'gene'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "human_df = pd.read_csv(\"human_ppi_edges_filtered.csv\")  \n",
    "\n",
    "G = nx.Graph()\n",
    "for _, row in human_df.iterrows():\n",
    "    G.add_edge(row['protein1_gene'], row['protein2_gene'])\n",
    "\n",
    "centrality = nx.degree_centrality(G)\n",
    "centrality_df = pd.DataFrame.from_dict(centrality, orient='index', columns=['centrality']).reset_index()\n",
    "centrality_df = centrality_df.rename(columns={'index': 'gene'})\n",
    "\n",
    "centrality_df.to_csv(\"hub_genes.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa27324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "centrality_df = pd.read_csv(\"hub_genes.csv\")  # gene, centrality\n",
    "centrality_df = centrality_df[['gene', 'centrality']]\n",
    "\n",
    "conservation_df = pd.read_csv(\"viral_target_conservation_ratios.csv\")  # gene, conservation_ratio\n",
    "conservation_df = conservation_df[['gene', 'conservation_ratio']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(centrality_df, conservation_df, on='gene', how='inner')\n",
    "print(f\"✅ Merged {len(merged_df)} genes with both centrality and conservation scores\")\n",
    "print(merged_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e058cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "merged_df[['centrality_norm', 'conservation_norm']] = scaler.fit_transform(\n",
    "    merged_df[['centrality', 'conservation_ratio']]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f3c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['final_score'] = 0.5 * merged_df['centrality_norm'] + 0.5 * merged_df['conservation_norm']\n",
    "\n",
    "merged_df = merged_df.sort_values(by='final_score', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df3d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"final_prioritized_viral_targets.csv\", index=False)\n",
    "\n",
    "print(\"🎯 Top candidates:\")\n",
    "print(merged_df[['gene', 'centrality', 'conservation_ratio', 'final_score']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e439f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "merged_df = pd.read_csv(\"final_prioritized_viral_targets.csv\")\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    x='centrality', \n",
    "    y='conservation_ratio', \n",
    "    data=merged_df, \n",
    "    hue='final_score', \n",
    "    size='final_score', \n",
    "    palette='viridis', \n",
    "    sizes=(20, 200),\n",
    "    edgecolor='k', \n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "plt.title(\"Conservation Ratio vs Centrality for SARS-CoV-2 Targets\", fontsize=14)\n",
    "plt.xlabel(\"Degree Centrality (Human PPI)\", fontsize=12)\n",
    "plt.ylabel(\"Conservation Ratio (Human-Mouse)\", fontsize=12)\n",
    "plt.legend(title=\"Final Score\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"scatter_conservation_centrality.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
